{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain_ollama import ChatOllama\n",
    "from typing import TypedDict, Optional\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Define State for the Interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state structure for interview process\n",
    "class GraphState(TypedDict):\n",
    "    all_history: Optional[str] = None\n",
    "    history: Optional[str] = None\n",
    "    result: Optional[str] = None\n",
    "    final_result: Optional[str] = None\n",
    "    total_questions: Optional[int] = None\n",
    "    interviewer: Optional[str] = None\n",
    "    candidate: Optional[str] = None\n",
    "    current_question: Optional[str] = None\n",
    "    current_answer: Optional[str] = None\n",
    "    round: Optional[int] = None\n",
    "    total_rounds: Optional[int] = None\n",
    "    total_questions_per_round: Optional[int] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ollama Model\n",
    "model = ChatOllama(\n",
    "    model='llama3.1',   # Specify the model (Llama 3.1)\n",
    "    temperature=0.8,    # Control creativity (higher is more creative)\n",
    "    num_predict=256     # Limit the number of tokens generated\n",
    ")\n",
    "\n",
    "# Function to generate response from LLM\n",
    "def llm(prompt: str) -> str:\n",
    "    response = model.predict(prompt)  \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Interview Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interview prompts\n",
    "prompt_interviewer = \"You're an interviewer. You need to interview a human for the {} role. This is the interview so far:\\n{}\\nAsk your next question. Don't repeat questions. Output just the question.\"\n",
    "prompt_result = \"Evaluate the complete performance of the candidate. Provide a rating at the end of the interview from 1 to 10 and a one-line explanation. The interview:\\n{}\"\n",
    "prompt_verdict = \"Based on the entire interview, should the candidate be selected? Respond with 'Yes' or 'No' and provide a one-line reason. The interview:\\n{}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Interview Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle AI's question generation\n",
    "def handle_question(state):\n",
    "    \"\"\" Generates a question for the candidate based on the role and conversation history \"\"\"\n",
    "    history = state.get('history', '').strip()\n",
    "    role = state.get('interviewer', '').strip()\n",
    "    candidate = state.get('candidate', '').strip()\n",
    "\n",
    "    prompt = prompt_interviewer.format(role, candidate, history)\n",
    "    question = llm(prompt)  \n",
    "\n",
    "    print(f\"\\nAI Interviewer: {question}\\n\")\n",
    "    time.sleep(0.5)  # Small pause for readability\n",
    "\n",
    "    return {\n",
    "        \"history\": history + '\\n\\n' + question,\n",
    "        \"current_question\": question,\n",
    "        \"total_questions\": state.get('total_questions', 0) + 1\n",
    "    }\n",
    "\n",
    "# Function to handle candidate's response\n",
    "def handle_response(state):\n",
    "    \"\"\" Collects the candidate's answer from user input \"\"\"\n",
    "    history = state.get('history', '').strip()\n",
    "    question = state.get('current_question', '').strip()\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    answer = input(\"Your Answer: \")  \n",
    "\n",
    "    return {\n",
    "        \"history\": history + '\\n\\n' + answer,\n",
    "        \"current_answer\": answer\n",
    "    }\n",
    "\n",
    "# Function to evaluate the interview and give feedback\n",
    "def handle_result(state):\n",
    "    \"\"\" Evaluates the candidate's overall performance and generates feedback \"\"\"\n",
    "    history = state.get('history', '').strip()\n",
    "    interviewer = state.get('interviewer', '').strip()\n",
    "\n",
    "    prompt = prompt_result.format(history)\n",
    "    result = llm(prompt)\n",
    "    all_history = state.get('all_history', '').strip()\n",
    "\n",
    "    return {\n",
    "        \"result\": state.get('result', '') + '\\n' + result,\n",
    "        \"history\": 'Nothing',\n",
    "        \"all_history\": all_history + '\\n\\nInterviewed by ' + interviewer + '\\n' + history,\n",
    "        'final_result': result\n",
    "    }\n",
    "\n",
    "# Function to determine final selection decision\n",
    "def handle_selection(state):\n",
    "    \"\"\" Determines if the candidate is selected or not based on the interview performance \"\"\"\n",
    "    result = state.get('result', '').strip()\n",
    "    prompt = prompt_verdict.format(result)\n",
    "    verdict = llm(prompt)\n",
    "\n",
    "    return {\"final_result\": verdict}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Workflow & Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes to workflow\n",
    "workflow.add_node(\"handle_question\", handle_question)\n",
    "workflow.add_node(\"handle_response\", handle_response)\n",
    "workflow.add_node(\"handle_result\", handle_result)\n",
    "workflow.add_node(\"handle_selection\", handle_selection)\n",
    "\n",
    "# Function to check if more questions are needed\n",
    "def check_conv_length(state):\n",
    "    \"\"\" Checks if the candidate has answered fewer than 5 questions \"\"\"\n",
    "    if state.get(\"total_questions\", 0) < 5:\n",
    "        return \"handle_question\"\n",
    "    else:\n",
    "        return \"handle_result\"\n",
    "\n",
    "# Function to check if interview is complete\n",
    "def check_rounds(state):\n",
    "    \"\"\" Checks if the interview should continue or move to final selection \"\"\"\n",
    "    if state.get(\"total_questions\", 0) >= 5 and state.get(\"total_rounds\", 1) == 1:\n",
    "        return \"handle_selection\"\n",
    "    else:\n",
    "        return \"handle_question\"\n",
    "\n",
    "# Add conditional edges for handling responses\n",
    "workflow.add_conditional_edges(\"handle_response\", check_conv_length, {\n",
    "    \"handle_question\": \"handle_question\",\n",
    "    \"handle_result\": \"handle_result\"\n",
    "})\n",
    "\n",
    "# Add conditional edges for handling results\n",
    "workflow.add_conditional_edges(\"handle_result\", check_rounds, {\n",
    "    \"handle_question\": \"handle_question\",\n",
    "    \"handle_selection\": \"handle_selection\"\n",
    "})\n",
    "\n",
    "# Set the entry point for the workflow\n",
    "workflow.set_entry_point(\"handle_question\")\n",
    "workflow.add_edge('handle_question', \"handle_response\")\n",
    "workflow.add_edge('handle_selection', END)\n",
    "\n",
    "# Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Interview (run everytime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Interviewer: What do you think are some important qualities that make a good classmate?\n",
      "\n",
      "Question: What do you think are some important qualities that make a good classmate?\n",
      "\n",
      "AI Interviewer: What do you think are some qualities that make a good friend?\n",
      "\n",
      "Question: What do you think are some qualities that make a good friend?\n",
      "\n",
      "AI Interviewer: What do you think are some important qualities that a good friend should have?\n",
      "\n",
      "Question: What do you think are some important qualities that a good friend should have?\n",
      "\n",
      "AI Interviewer: What do you think are some qualities that make a good friend?\n",
      "\n",
      "Question: What do you think are some qualities that make a good friend?\n",
      "\n",
      "AI Interviewer: Can you describe a time when you had to work with others on a group project?\n",
      "\n",
      "Question: Can you describe a time when you had to work with others on a group project?\n",
      "\n",
      "Final Feedback: No. The candidate's lack of depth in thinking, inability to provide real-world examples, and repetition throughout the interview outweigh their ability to articulate good qualities.\n",
      "\n",
      "Based on the interview, here is my evaluation of the candidate's performance:\n",
      "\n",
      "**Red flags:**\n",
      "\n",
      "* The candidate seems to be repeating themselves throughout the interview, without adding any new insights or examples. This suggests a lack of depth in their thinking and an inability to articulate their ideas clearly.\n",
      "* When asked about a time when they had to work with others on a group project, the candidate simply says \"nope.\" This is a missed opportunity for them to showcase their teamwork skills and provide a real-world example from their experience.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* The candidate has some good qualities in mind when it comes to being a classmate or friend, such as honesty, helpfulness, and emotional availability.\n",
      "* They are able to articulate these qualities clearly and concisely.\n",
      "\n",
      "**Rating:** 4/10\n",
      "\n",
      "\"candidate failed to demonstrate practical examples of teamwork and was overly repetitive in their responses.\"\n",
      "\n",
      "\n",
      "Interviewed by \n",
      "What do you think are some important qualities that make a good classmate?\n",
      "\n",
      "honest, friendly, helpful, mindful,  emotionally available, good at heart. these are some important qualities that make a good classmate\n",
      "\n",
      "What do you think are some qualities that make a good friend?\n",
      "\n",
      "helpful, one who guides in the right path, thruthful, remembers oo=ur talks\n",
      "\n",
      "What do you think are some important qualities that a good friend should have?\n",
      "\n",
      "everything that i said above.\n",
      "\n",
      "What do you think are some qualities that make a good friend?\n",
      "\n",
      "things that i mentioned above\n",
      "\n",
      "Can you describe a time when you had to work with others on a group project?\n",
      "\n",
      "nope\n"
     ]
    }
   ],
   "source": [
    "# Get job description input\n",
    "job_description = input(\"Enter the job description: \")\n",
    "\n",
    "# Initialize interview state\n",
    "conversation_state = {\n",
    "    'total_questions': 0,\n",
    "    'candidate': job_description,\n",
    "    'total_rounds': 1,\n",
    "}\n",
    "\n",
    "# Run the interview\n",
    "conversation_state = app.invoke(conversation_state)\n",
    "\n",
    "# Print final feedback\n",
    "final_feedback = conversation_state.get(\"final_result\")\n",
    "print(f\"\\nFinal Feedback: {final_feedback}\")\n",
    "print(conversation_state['result'])\n",
    "print(conversation_state['all_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
